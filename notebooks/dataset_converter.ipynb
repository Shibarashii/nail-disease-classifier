{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing label maps (.pbtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded Labels (without Lindsay's Nail): {0: 'Acral Lentiginous Melanoma', 1: 'Beaus Line', 2: 'Blue Finger', 3: 'Clubbing', 4: 'Healthy Nail', 5: 'Koilonychia', 7: 'Muehrckes Lines', 8: 'Onychogryphosis', 9: 'Pitting', 10: 'Terry-s Nail'}\n"
     ]
    }
   ],
   "source": [
    "def load_label_map(label_map_path, exclude_label=\"Lindsay-s Nail\"):\n",
    "    with open(label_map_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    label_map = {}\n",
    "    matches = re.findall(r'name:\\s*\\\"(.+?)\\\",\\s*id:\\s*(\\d+),', content)  # Adjusted regex\n",
    "\n",
    "    for match in matches:\n",
    "        label_name = match[0]\n",
    "        label_id = int(match[1])\n",
    "\n",
    "        if label_name != exclude_label:  # Skip Lindsay's Nail because it only has 1 item\n",
    "            label_map[label_id - 1] = label_name  # Convert to 0-based index\n",
    "\n",
    "    return label_map\n",
    "\n",
    "# Path to label map\n",
    "label_map_path = \"dataset/train/Diseases_label_map.pbtxt\"\n",
    "CLASS_LABELS = load_label_map(label_map_path)\n",
    "\n",
    "# Debug: Print Loaded Labels\n",
    "if CLASS_LABELS:\n",
    "    print(\"âœ… Loaded Labels (without Lindsay's Nail):\", CLASS_LABELS)\n",
    "else:\n",
    "    print(\"âŒ ERROR: No labels loaded. Check the pbtxt file path or format!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to Split Set (Test, Train, Validation)\n",
    "This code converts the .tfrecords from the dataset into a Directory-Based Dataset which is split into the ``train``, ``test``, and ``valid`` sets. The output directory is at ``data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 17:50:33.618918: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train set done! Images saved in: converted_dataset/train\n",
      "ðŸ”„ Processing valid set...\n",
      "âœ… Valid set done! Images saved in: converted_dataset/valid\n",
      "ðŸ”„ Processing test set...\n",
      "âœ… Test set done! Images saved in: converted_dataset/test\n",
      "ðŸŽ‰ All datasets processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Paths to datasets\n",
    "tfrecord_paths = {\n",
    "    \"train\": \"misc/data_src/train/Diseases.tfrecord\",\n",
    "    \"valid\": \"misc/data_src/valid/Diseases.tfrecord\",\n",
    "    \"test\": \"misc/data_src/test/Diseases.tfrecord\",\n",
    "}\n",
    "\n",
    "output_dirs = {\n",
    "    \"train\": \"data/train\",\n",
    "    \"valid\": \"data/valid\",\n",
    "    \"test\": \"data/test\",\n",
    "}\n",
    "\n",
    "# Ensure output directories exist\n",
    "for split, output_dir in output_dirs.items():\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def _parse_tfrecord(example_proto):\n",
    "    feature_description = {\n",
    "        \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image/object/class/label\": tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    # Decode image\n",
    "    image = tf.io.decode_jpeg(example[\"image/encoded\"], channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.cast(image, tf.uint8).numpy()\n",
    "\n",
    "    # Convert sparse tensor to dense\n",
    "    labels = tf.sparse.to_dense(example[\"image/object/class/label\"]).numpy()\n",
    "\n",
    "    # Exclude missing labels\n",
    "    if len(labels) > 0:\n",
    "        label_id = labels[0] - 1  # Convert to 0-based index\n",
    "        label_name = CLASS_LABELS.get(label_id)\n",
    "\n",
    "        # Exclude images with missing or unknown labels\n",
    "        if label_name is None:\n",
    "            return None\n",
    "\n",
    "        return image, label_name\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Process all datasets\n",
    "for split, tfrecord_path in tfrecord_paths.items():\n",
    "    output_dir = output_dirs[split]\n",
    "    print(f\"ðŸ”„ Processing {split} set...\")\n",
    "\n",
    "    raw_dataset = tf.data.TFRecordDataset([tfrecord_path])\n",
    "    for i, raw_record in enumerate(raw_dataset):\n",
    "        parsed = _parse_tfrecord(raw_record)\n",
    "        if parsed:\n",
    "            image, label_name = parsed\n",
    "            class_dir = os.path.join(output_dir, label_name)\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "            filename = os.path.join(class_dir, f\"{i}.jpg\")\n",
    "            cv2.imwrite(filename, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))  # Fix color issue\n",
    "\n",
    "    print(f\"âœ… {split.capitalize()} set done! Images saved in: {output_dir}\")\n",
    "\n",
    "print(\"ðŸŽ‰ All datasets processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Set\n",
    "This code converts the .tfrecords into one whole Directory-Based dataset. The output is at ``combined_dataset``\n",
    "However, this is optional only, if we want a randomized training and validation set. We did not include this in our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing train set...\n",
      "âœ… Train set done! Images saved in: combined_dataset\n",
      "ðŸ”„ Processing valid set...\n",
      "âœ… Valid set done! Images saved in: combined_dataset\n",
      "ðŸ”„ Processing test set...\n",
      "âœ… Test set done! Images saved in: combined_dataset\n",
      "ðŸŽ‰ All datasets processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Paths to TFRecord files\n",
    "tfrecord_paths = {\n",
    "    \"train\": \"dataset/train/Diseases.tfrecord\",\n",
    "    \"valid\": \"dataset/valid/Diseases.tfrecord\",\n",
    "    \"test\": \"dataset/test/Diseases.tfrecord\",\n",
    "}\n",
    "\n",
    "# Output folder for FastAI\n",
    "output_dir = \"combined_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Process all datasets into one folder\n",
    "for split, tfrecord_path in tfrecord_paths.items():\n",
    "    print(f\"ðŸ”„ Processing {split} set...\")\n",
    "\n",
    "    raw_dataset = tf.data.TFRecordDataset([tfrecord_path])\n",
    "    for i, raw_record in enumerate(raw_dataset):\n",
    "        parsed = _parse_tfrecord(raw_record)\n",
    "        if parsed:\n",
    "            image, label_name = parsed\n",
    "            class_dir = os.path.join(output_dir, label_name)\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "            filename = os.path.join(class_dir, f\"{split}_{i}.jpg\")  # Prefix to avoid conflicts\n",
    "            cv2.imwrite(filename, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))  # Fix color issue\n",
    "\n",
    "    print(f\"âœ… {split.capitalize()} set done! Images saved in: {output_dir}\")\n",
    "\n",
    "print(\"ðŸŽ‰ All datasets processed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
